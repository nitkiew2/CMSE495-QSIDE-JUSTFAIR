{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadr\n",
    "import numpy as np\n",
    "import mplcursors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510758d",
   "metadata": {},
   "source": [
    "Import data\n",
    "\n",
    "Start by running locally, we'll work our way up to reading from the internet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f14851",
   "metadata": {},
   "source": [
    "Overarching design for this toolbox is as follows.\n",
    "\n",
    "First, we design a state class to house necessary information.  Now, the issue is each state has different naming conventions on how it stores its data, so we then generate a set of easy to understand names to use.  After we have the easy-to-use names, we build a map that maps the easy-to-use names to the specific term the state uses.  From there, we can now write generalizable functions in terms of the easy-to-use names, and it works for every state as long as the map is set up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a1452",
   "metadata": {},
   "source": [
    "## General Terms\n",
    "\n",
    "First, we design a universal set of names to refer to information that is needed for our analysis.  These general terms are:\n",
    "1.\tYear: the year the sentencing occurred.\n",
    "2.\tCounty: the county of where the sentencing occurred.\n",
    "3.\tDistrict: the district the sentencing occurred.\n",
    "4.\tRace: the race of the individual sentenced\n",
    "5.\tDeparture: what kind of departure, if any occurred in the sentencing.  Levels could be Above Departure (sentencing greater than guideline), Within Range,  Below Range (sentence is below the guideline), or Indeterminable.\n",
    "6.\tJudge: the name of the Judge that sentenced the individual\n",
    "7.\tSex: the sex of the individual sentenced\n",
    "\n",
    "The idea here is we have these general, understandable terms.  State datasets vary from state to state, so we build a map to relate the general, usable term to the specific term the state uses.  This is useful for two reasons\n",
    "\n",
    "1.\tThis map makes writing functions universal because of the maps.  Since we know that we can use, for example, Year to access the year data, we can always use Year rather than have to write a new function for every state.\n",
    "2.\tIt makes reading and writing code easy to understand.  Rather than knowing durdep means duration in the Minnesota dataset, all you have to know is the general terms and the maps do all the hard work of relating the easy term to the hard one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b61ebe9",
   "metadata": {},
   "source": [
    "# Class State\n",
    "Designed to be a container to hold all the necessary information for a specific state.  This class has 3 attributes\n",
    "* Name:  Stores the name of the state\n",
    "* Data: stores the dataframe for that state’s data\n",
    "* Paths: this is a dictionary that maps the easy to use names to the specific names the state’s dataset uses.\n",
    "* Paths always has 1 of the two formats:\n",
    "    1. paths\\[general term\\] = \\[specific_state_term\\]\n",
    "    2. paths\\[general term\\] = \\[specific_state_term, dictionary describing the levels of that term\\]\n",
    "    \n",
    "State objects are the core of this toolbox.  Every function is written with a state object being passed in.  The function takes the state object, then uses the genral terms, paths, and the states data to produce the desiered output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, inp_name, inp_data, inp_paths):\n",
    "        self.name = inp_name\n",
    "        \n",
    "        self.data = inp_data  # pandas dataframe object\n",
    "        \n",
    "        self.paths = inp_paths  # dictionary object.  \n",
    "        # Always follows the format useful_id --> (name_in_data, dict(levels)).\n",
    "        # Levels doesn't always exist, but is needed for variables like departure\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ebd9ea",
   "metadata": {},
   "source": [
    "This code is setting up the minnesota state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a85006",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {}  # dictionary to hold all states.  maps dict['state name'] --> state object for that state\n",
    "paths = {}  # temporary paths dicitonary that will be passed into the creation of minnesota state object\n",
    "paths['county'] = ['countyname', None]\n",
    "paths['year'] = ['sentyear', None]\n",
    "paths['district'] = ['district', None]\n",
    "paths['race'] = ['race', {0:'NA', \n",
    "                                 'white':'White', \n",
    "                                 'black':'Black', \n",
    "                                 'amind':'American Indian',\n",
    "                                 'hispanic': 'Hispanic',\n",
    "                                 'asian': 'Asian',\n",
    "                                 'other': ' Other',\n",
    "                                 None: 'Unknown'}]\n",
    "paths['departure'] = ['durdep', {0:'Within Range', \n",
    "                                 1:'Above Departure', \n",
    "                                 2:'Below Range', \n",
    "                                 3:'Missing, Indeterminable, or Inapplicable'}]\n",
    "paths['judge'] = ['judge', None]\n",
    "paths['sex'] = ['sex', {1: 'male', 2: 'female'}]\n",
    "paths['age'] = ['Agecat', {1: 'under 18', 2: '18-21', 3: '22-25', 4: '26-30',5: '31-40',6: '41-50',7: '51+'}]\n",
    "\n",
    "#now that we have the information, we create the minnesota state object and add it to the states dictionary\n",
    "states['minnesota'] = State('minnesota', pd.read_csv('allmnclean.csv', low_memory = False), paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7530b4",
   "metadata": {},
   "source": [
    "# Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_departures(departure_output, departure_porportions, subgroup, s = True):\n",
    "    subgroup_str = ''\n",
    "    for item in subgroup:\n",
    "        subgroup_str += str(item) + ' '\n",
    "    if s:  \n",
    "        subgroup_str = subgroup_str[:-1]\n",
    "        subgroup_str+='s'\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize = (10,7))\n",
    "    bar_colors = ['red', 'grey', 'blue', 'teal']\n",
    "    \n",
    "    barh = ax.barh(departure_output, departure_porportions, color=bar_colors)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_xlabel('Percentage')\n",
    "    \n",
    "    ##ax.bar_label(barh)\n",
    "    ##for bars in ax.containers:\n",
    "        ##ax.bar_label(barh)\n",
    "    \n",
    "    ttl = 'Porportional sentences for '+ subgroup_str\n",
    "    ax.set_title(ttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3432ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_departures_stacked(x_values_list, y_values_list, subgroup, legend, s = True):\n",
    "    subgroup_str = ''\n",
    "    for item in subgroup:\n",
    "        subgroup_str += str(item) + ' '\n",
    "    if s:  \n",
    "        subgroup_str = subgroup_str[:-1]\n",
    "        subgroup_str+='s'\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize = (10,1 * len(x_values_list)))\n",
    "    \n",
    "    bar_colors = ['red', 'grey', 'blue', 'teal']\n",
    "    \n",
    "    b = np.zeros(len(x_values_list))\n",
    "    for i in range(len(y_values_list)):\n",
    "        ax.barh(x_values_list, y_values_list[i], left = b, color = bar_colors[i], label = legend[i])\n",
    "        b += y_values_list[i]\n",
    "    ax.set_xlabel('Percentage')\n",
    "    ttl = 'Porportional sentences for '+ subgroup_str\n",
    "    ax.set_title(ttl)\n",
    "    ax.legend(bbox_to_anchor = (1.45, 0.6), loc='center right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c51e8e",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_years(stateobj, years):\n",
    "    '''\n",
    "    Every funciton has a years to filter parameter, so we are building a function here because:\n",
    "    1.  if we have to edit it, we only have to edit it here\n",
    "    2.  saves us time from rewriting this a bunch\n",
    "    Parameters:\n",
    "    stateobj: a state object\n",
    "    years: the specified years.  Either a range or none\n",
    "    '''\n",
    "    subset_dat = stateobj.data\n",
    "    if years != None:  \n",
    "        # if the user specifies a year range, filter the data for those years\n",
    "        subset_dat = stateobj.data[stateobj.paths['year'] == years]\n",
    "    return subset_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cfb078",
   "metadata": {},
   "source": [
    "# Analysis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8effb6",
   "metadata": {},
   "source": [
    "### State aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057867b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_aggregate(stateobj, years = None):\n",
    "    subset_dat = filter_years(stateobj, years)\n",
    "        \n",
    "    counts = subset_dat.groupby(stateobj.paths['departure'][0]).count()\n",
    "    counts = counts.rename(stateobj.paths['departure'][1])\n",
    "    counts = counts.iloc[:,0]\n",
    "     \n",
    "    order_of_outputs = ['Above Departure', 'Within Range', 'Below Range', 'Missing, Indeterminable, or Inapplicable']\n",
    "    porportions_list = []\n",
    "    for item in order_of_outputs:\n",
    "        porportions_list.append(round((100 * counts.at[item]  /  subset_dat.shape[0]),1))\n",
    "    \n",
    "    plot_departures(order_of_outputs, porportions_list, [stateobj.name], s = False)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61819108",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state_aggregate(states['minnesota'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c4a3a",
   "metadata": {},
   "source": [
    "## Race profile\n",
    "\n",
    "Grouping by race, what is the breakdown for sentencing in this state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a8a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_profile(stateobj, years = None):\n",
    "    # we should have a subplots vs stacked parameter here maybe?  either do lots of individual graphs or stacked\n",
    "    subset_dat = (stateobj, years)\n",
    "    \n",
    "    #grouping by departure and race\n",
    "    #divide by count(race) for racial percentages, to get counts, remove the denominator\n",
    "    counts = round(100 * subset_dat.groupby([stateobj.paths['race'][0], stateobj.paths['departure'][0]]).count() / \n",
    "                   subset_dat.groupby([stateobj.paths['race'][0]]).count(), 1)\n",
    "    \n",
    "    # renames the values to have a description\n",
    "    counts = counts.rename(stateobj.paths['race'][1], level = 0)\n",
    "    counts = counts.rename(stateobj.paths['departure'][1], level = 1)\n",
    "    counts = counts.iloc[:,0]  # all columns are the same, so we pull the first one\n",
    "    \n",
    "    order_of_outputs = ['Above Departure', 'Within Range', 'Below Range', 'Missing, Indeterminable, or Inapplicable']\n",
    "    \n",
    "    #get the order of the races four out output, may make this a function\n",
    "    order_of_races = []\n",
    "    for idx in counts.index:  #idx is a tuple of (race, departure_type)\n",
    "        if idx[0] not in order_of_races:\n",
    "            order_of_races.append(idx[0])\n",
    "            \n",
    "    # we want our data to be in the shape: number of levels in output (departure) x number of subgroups (race)        \n",
    "    percentages = np.zeros((len(order_of_outputs), len(order_of_races)))\n",
    "    for dep in range(len(order_of_outputs)):\n",
    "        for race in range(len(order_of_races)):\n",
    "            percentages[dep, race] = counts.loc[(order_of_races[race], order_of_outputs[dep]),]\n",
    "    #warning, potential for keyerror above if sonehow we have a race that doesn't have all departure levels        \n",
    "    \n",
    "    plot_departures_stacked(order_of_races, percentages, [stateobj.name, 'race'], order_of_outputs)\n",
    "    \n",
    "    return counts, percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116ce7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf292cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac39a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
