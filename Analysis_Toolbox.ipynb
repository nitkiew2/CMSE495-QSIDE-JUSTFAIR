{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import pyreadr\n",
    "import numpy as np\n",
    "import mplcursors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510758d",
   "metadata": {},
   "source": [
    "Import data\n",
    "\n",
    "Start by running locally, we'll work our way up to reading from the internet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f14851",
   "metadata": {},
   "source": [
    "Overarching design for this toolbox is as follows.\n",
    "\n",
    "First, we design a state class to house necessary information.  Now, the issue is each state has different naming conventions on how it stores its data, so we then generate a set of easy to understand names to use.  After we have the easy-to-use names, we build a map that maps the easy-to-use names to the specific term the state uses.  From there, we can now write generalizable functions in terms of the easy-to-use names, and it works for every state as long as the map is set up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a1452",
   "metadata": {},
   "source": [
    "## General Terms\n",
    "\n",
    "First, we design a universal set of names to refer to information that is needed for our analysis.  These general terms are:\n",
    "1.\tYear: the year the sentencing occurred.\n",
    "2.\tCounty: the county of where the sentencing occurred.\n",
    "3.\tDistrict: the district the sentencing occurred.\n",
    "4.\tRace: the race of the individual sentenced\n",
    "5.\tDeparture: what kind of departure, if any occurred in the sentencing.  Levels could be Above Departure (sentencing greater than guideline), Within Range,  Below Range (sentence is below the guideline), or Indeterminable.\n",
    "6.\tJudge: the name of the Judge that sentenced the individual\n",
    "7.\tSex: the sex of the individual sentenced\n",
    "\n",
    "The idea here is we have these general, understandable terms.  State datasets vary from state to state, so we build a map to relate the general, usable term to the specific term the state uses.  This is useful for two reasons\n",
    "\n",
    "1.\tThis map makes writing functions universal because of the maps.  Since we know that we can use, for example, Year to access the year data, we can always use Year rather than have to write a new function for every state.\n",
    "2.\tIt makes reading and writing code easy to understand.  Rather than knowing durdep means duration in the Minnesota dataset, all you have to know is the general terms and the maps do all the hard work of relating the easy term to the hard one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b61ebe9",
   "metadata": {},
   "source": [
    "# Class State\n",
    "Designed to be a container to hold all the necessary information for a specific state.  This class has 3 attributes\n",
    "* Name:  Stores the name of the state\n",
    "* Data: stores the dataframe for that state’s data\n",
    "* Paths: this is a dictionary that maps the easy to use names to the specific names the state’s dataset uses.\n",
    "* Paths always has 1 of the two formats:\n",
    "    1. paths\\[general term\\] = \\[specific_state_term\\]\n",
    "    2. paths\\[general term\\] = \\[specific_state_term, dictionary describing the levels of that term\\]\n",
    "    \n",
    "State objects are the core of this toolbox.  Every function is written with a state object being passed in.  The function takes the state object, then uses the genral terms, paths, and the states data to produce the desiered output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, inp_name, inp_data, inp_paths, \n",
    "                 order_of_outputs = ['Above Departure', 'Within Range', 'Below Range', \n",
    "                                        'Missing, Indeterminable, or Inapplicable']):\n",
    "        self.name = inp_name\n",
    "        \n",
    "        self.data = inp_data  # pandas dataframe object\n",
    "        \n",
    "        self.paths = inp_paths  # dictionary object.  \n",
    "        # Always follows the format useful_id --> (name_in_data, dict(levels)).\n",
    "        # Levels doesn't always exist, but is needed for variables like departure\n",
    "        #path pairs are always (name_in_data, dict(levels)) or (name_in_data, None)\n",
    "        \n",
    "        self.order_of_outputs = order_of_outputs\n",
    "        #this is how you want to arrange your output on graphs\n",
    "        #is basically the order of the levels in paths[departure][1]\n",
    "        \n",
    "        self.average_percents= []  #list, for all years, state averages for all people\n",
    "        self.yearly_average_percents = {}  # dictionary, state averages for all people for each year\n",
    "                                             # format of: year (int) --> [averages_list]\n",
    "        \n",
    "        self.years = np.sort(self.data[self.paths['year'][0]].unique())  # generate a sorted list of years for data\n",
    "\n",
    "        \n",
    "        \n",
    "        ###  get average_percents\n",
    "        counts = self.data.groupby(self.paths['departure'][0]).count()\n",
    "        counts = counts.rename(self.paths['departure'][1])\n",
    "        counts = counts.iloc[:,0]\n",
    "\n",
    "        for item in self.order_of_outputs:\n",
    "            self.average_percents.append(round((100 * counts.loc[item]  /  self.data.shape[0]),2))\n",
    "        \n",
    "        ### get yearly_average_percents\n",
    "        for year in self.years:\n",
    "            subset_dat = self.data[ self.data[self.paths['year'][0] ] == year]\n",
    "            counts = subset_dat.groupby(self.paths['departure'][0]).count()\n",
    "            counts = counts.rename(self.paths['departure'][1])\n",
    "            counts = counts.iloc[:,0]\n",
    "            \n",
    "            percentages = []\n",
    "            for item in self.order_of_outputs:\n",
    "                percentages.append(round((100 * counts.loc[item]  /  subset_dat.shape[0]),2))\n",
    "            self.yearly_average_percents[year] = percentages\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ebd9ea",
   "metadata": {},
   "source": [
    "This code is setting up the minnesota state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a85006",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {}  # dictionary to hold all states.  maps dict['state name'] --> state object for that state\n",
    "paths = {}  # temporary paths dicitonary that will be passed into the creation of minnesota state object\n",
    "paths['county'] = ['countyname', None]\n",
    "paths['year'] = ['sentyear', None]\n",
    "paths['district'] = ['district', None]\n",
    "paths['race'] = ['race', {0:'NA', \n",
    "                                 'white':'White', \n",
    "                                 'black':'Black', \n",
    "                                 'amind':'American Indian',\n",
    "                                 'hispanic': 'Hispanic',\n",
    "                                 'asian': 'Asian',\n",
    "                                 'other': ' Other',\n",
    "                                 None: 'Unknown'}]\n",
    "paths['departure'] = ['durdep', {0:'Within Range', \n",
    "                                 1:'Above Departure', \n",
    "                                 2:'Below Range', \n",
    "                                 3:'Missing, Indeterminable, or Inapplicable'}]\n",
    "paths['judge'] = ['judge', None]\n",
    "paths['sex'] = ['sex', {1: 'Male', 2: 'Female'}]\n",
    "paths['age'] = ['Agecat', {1: 'Under 18', 2: '18-21', 3: '22-25', 4: '26-30',5: '31-40',6: '41-50',7: '51+'}]\n",
    "\n",
    "#now that we have the information, we create the minnesota state object and add it to the states dictionary\n",
    "states['minnesota'] = State('minnesota', pd.read_csv('allmnclean.csv', low_memory = False), paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7530b4",
   "metadata": {},
   "source": [
    "# Plotting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b61c10",
   "metadata": {},
   "source": [
    "## horizontal bar graph\n",
    "This function is used to plot a horizontal bar graph to view results.\n",
    "\n",
    "Parameters:\n",
    "* departure_labels: the labels on our departure variable.  This is the x labels\n",
    "* departure_porportions: the porportions for each label.  This is the y label.\n",
    "* subgroup: the subgroup that this bar graph corrosponds to (used in the title).  Only used when looking at more than one level.\n",
    "* s: for formatting, adds an s to the end of the title string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_departures_bar(departure_labels, departure_porportions, subgroup, s = True):\n",
    "    subgroup_str = ''\n",
    "    for item in subgroup:\n",
    "        subgroup_str += str(item) + ' '\n",
    "    if s:  \n",
    "        subgroup_str = subgroup_str[:-1]\n",
    "        subgroup_str+='s'\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize = (10,7))\n",
    "    colors = ['lightcoral', 'lightgrey', 'cornflowerblue', 'turquoise']\n",
    "    \n",
    "    barh = ax.barh(departure_labels, departure_porportions, color=colors)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_xlabel('Percentage')\n",
    "    \n",
    "    ax.bar_label(barh, fmt='%.2f%%')\n",
    "    ax.set_xlim(right=100)\n",
    "    \n",
    "    ttl = 'Porportional sentences for '+ subgroup_str\n",
    "    ax.set_title(ttl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e158ffe",
   "metadata": {},
   "source": [
    "## Pie chart\n",
    "\n",
    "This function is used to plot a pie chart to view results.  This is just like the hoizontal bar graph, but a pie chart.\n",
    "\n",
    "Parameters:\n",
    "* departure_labels: the labels on our departure variable.  This is the x labels\n",
    "* departure_porportions: the porportions for each label.  This is the y label.\n",
    "* subgroup: the subgroup that this bar graph corrosponds to (used in the title).  Only used when looking at more than one level.\n",
    "* s: for formatting, adds an s to the end of the title string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd04833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_departures_pie(departure_labels, departure_porportions, subgroup, s = True):\n",
    "    subgroup_str = ''\n",
    "    for item in subgroup:\n",
    "        subgroup_str += str(item) + ' '\n",
    "    if s:  \n",
    "        subgroup_str = subgroup_str[:-1]\n",
    "        subgroup_str+='s'\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize = (10,7))\n",
    "    colors = ['lightcoral', 'lightgrey', 'cornflowerblue', 'turquoise']\n",
    "    \n",
    "    ax.pie(departure_porportions, labels=departure_labels, autopct='%1.1f%%', colors = colors)\n",
    "    \n",
    "    \n",
    "    ttl = 'Porportional sentences for '+ subgroup_str\n",
    "    ax.set_title(ttl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26050b2b",
   "metadata": {},
   "source": [
    "## stacked bar graph\n",
    "This function is used to plot a stacked horizontal bar graph to view results.\n",
    "\n",
    "Parameters:\n",
    "* x_values_list: the labels on our departure variable.  This is the x labels.  in the format of an 1 x number of subgroups\n",
    "* y_values_list: the porportions for each label.  This is the y label.  In the format of (number of subgroups) x (number of items in the state's order of outouts)\n",
    "* subgroup: the subgroup that this bar graph corrosponds to (used in the title).  Only used when looking at more than one level.\n",
    "* s: for formatting, adds an s to the end of the title string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3432ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_departures_stacked(x_values_list, y_values_list, subgroup, legend, s = True):\n",
    "    subgroup_str = ''\n",
    "    for item in subgroup:\n",
    "        subgroup_str += str(item) + ' '\n",
    "    if s:  \n",
    "        subgroup_str = subgroup_str[:-1]\n",
    "        subgroup_str+='s'\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize = (12, 1 * len(x_values_list)))\n",
    "    \n",
    "    bar_colors = ['lightcoral', 'lightgrey', 'cornflowerblue', 'turquoise']\n",
    "    \n",
    "    b = np.zeros(len(x_values_list))\n",
    "    for i in range(len(y_values_list)):\n",
    "        ax.barh(x_values_list, y_values_list[i], left = b, color = bar_colors[i], label = legend[i], edgecolor='black')\n",
    "        b += y_values_list[i]\n",
    "    ax.set_xlabel('Percentage')\n",
    "    ax.set_xlim((-5,105))\n",
    "    ttl = 'Porportional sentences for '+ subgroup_str\n",
    "    ax.set_title(ttl)\n",
    "    ax.legend(bbox_to_anchor = (1.45, 0.6), loc='center right')\n",
    "    \n",
    "\n",
    "    # For each patch (basically each rectangle within the bar), add a label.\n",
    "    #we are \n",
    "    len_to_beat = 0\n",
    "    if isinstance(y_values_list[0], float):\n",
    "        len_to_beat = 1\n",
    "    else:\n",
    "        len_to_beat = len(y_values_list[0])\n",
    "        \n",
    "    for i in range(len(ax.patches)):\n",
    "        bar = ax.patches[i]\n",
    "        if i < len_to_beat:  # above departure / first bar\n",
    "            ax.text(\n",
    "              bar.get_x() + bar.get_width()/2,\n",
    "              bar.get_y() + bar.get_height() / 2,\n",
    "              # This is actual value we'll show.\n",
    "              str(round(bar.get_width(),2)) + '%',\n",
    "              # Center the labels and style them a bit.\n",
    "              ha='right',\n",
    "              weight='bold',\n",
    "              size=11)\n",
    "        elif i < 3 * len_to_beat:  # second and third bars (in range, below range)\n",
    "            ax.text(\n",
    "              bar.get_x() + bar.get_width()/2,\n",
    "              bar.get_y() + bar.get_height() / 2,\n",
    "              # This is actual value we'll show.\n",
    "              str(round(bar.get_width(),2)) + '%',\n",
    "              # Center the labels and style them a bit.\n",
    "              ha='center',\n",
    "              weight='bold',\n",
    "              size=11)\n",
    "        else: # i % 4 == 3  last bar (missing, indeterminable, inapplicable)\n",
    "            ax.text(\n",
    "              bar.get_x() + bar.get_width()/2,\n",
    "              bar.get_y() + bar.get_height() / 2,\n",
    "              # This is actual value we'll show.\n",
    "              str(round(bar.get_width(),2)) + '%',\n",
    "              # Center the labels and style them a bit.\n",
    "              ha='left',\n",
    "              weight='bold',\n",
    "              size=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f9809",
   "metadata": {},
   "source": [
    "## Judge vs state bar graph\n",
    "Plots a comparison horizontal bar graph comparing the state to the judge in question.\n",
    "\n",
    "Parameters:\n",
    "* order_of_outputs: a state objects order_of_outputs variable, used to deterimine the order of bars on the chart\n",
    "* judge_averages: the judge's averages.  In the shape of 1 x (length of order of outputs)\n",
    "* state_avg_for_years: the state's averages.  In the shape of 1 x (length of order of outputs)\n",
    "* judge_name: name of the judge, for formatting the title\n",
    "* statename: name of the state, for formatting the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf906958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_judge_vs_state(order_of_outputs, judge_averages, state_avg_for_years, judge_name, statename):\n",
    "    x = np.arange(len(order_of_outputs))\n",
    "    y_data = {}\n",
    "    y_data[judge_name] = judge_averages\n",
    "    y_data[statename] = state_avg_for_years\n",
    "    \n",
    "    width = 0.35\n",
    "    multiplier = 0\n",
    "    \n",
    "    bar_colors = ['lightcoral', 'lightgrey', 'cornflowerblue', 'turquoise']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (10,7))\n",
    "\n",
    "    for attribute, measurement in y_data.items():\n",
    "        offset = width * multiplier\n",
    "        rects = ax.barh(x + offset, measurement, width, label=attribute, color = bar_colors, edgecolor='black')\n",
    "        ax.bar_label(rects, padding=3, fmt='%.2f%%' + '   ('+ attribute+')')\n",
    "        multiplier += 1\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_xlabel('percentage (%)')\n",
    "    ttl = 'Comparig ' + judge_name + ' sentancing to ' + statename + ' sentencing'\n",
    "    ax.set_title(ttl)\n",
    "    ax.set_yticks(x + width/2)\n",
    "    ax.set_yticklabels(order_of_outputs)\n",
    "    ax.set_xlim(0, 119)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de046d",
   "metadata": {},
   "source": [
    "## Judge vs state line graph\n",
    "Plots a line graphs comparing the state to the judge in question.\n",
    "\n",
    "Parameters:\n",
    "* stateobj.  A state object.  Used to access the state's anme and order of outputs.\n",
    "* ovarlapping years.  The years that the judge worked (whaich years of the state's data did the judge work in?)\n",
    "* judge_data_y: the judge's averages.  In the shape of (number of overlapping years) x (length of order of outputs)\n",
    "* state_data_y: the state's averages.  In the shape of (number of overlapping years) x (length of order of outputs)\n",
    "* judge_name: name of the judge, for formatting the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_judge_vs_state_trends(stateobj, overlapping_years, judge_data_y, state_data_y, judge_name):\n",
    "    colors = ['lightcoral', 'lightgrey', 'cornflowerblue', 'turquoise']\n",
    "    \n",
    "    for col in range(len(stateobj.order_of_outputs)):\n",
    "        fig, ax = plt.subplots(figsize=(10, 7))\n",
    "        ax.plot(overlapping_years, judge_data_y[:,col], label=judge_name, color = colors[col])\n",
    "        ax.plot(overlapping_years, state_data_y[:,col], '--', label=stateobj.name, color = colors[col])\n",
    "        ttl = 'Comparig ' + judge_name + ' and' + stateobj.name + ' on ' + stateobj.order_of_outputs[col]\n",
    "        ax.set_title(ttl)\n",
    "        ax.set_xlabel('year')\n",
    "        ax.set_ylabel('percentage (%)')\n",
    "        ax.legend(loc = 'upper right')\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    for col in range(len(stateobj.order_of_outputs)):\n",
    "        ax.plot(overlapping_years, judge_data_y[:,col] - state_data_y[:,col], \n",
    "                label=stateobj.order_of_outputs[col], color = colors[col])\n",
    "    ax.axhline(y = 0, color = 'black')\n",
    "    \n",
    "    ttl = 'Comparig ' + judge_name + ' difffernece from ' + stateobj.name + ' levels'\n",
    "    ax.set_title(ttl)\n",
    "    ax.set_xlabel('year')\n",
    "    ax.set_ylabel('percentage (%)')\n",
    "    ax.legend(loc = 'upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c51e8e",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44969ef2",
   "metadata": {},
   "source": [
    "## Filter years\n",
    "returns a filtered copy of a state's data for the desired years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_years(stateobj, years):\n",
    "    '''\n",
    "    Every funciton has a years to filter parameter, so we are building a function here because:\n",
    "    1.  if we have to edit it, we only have to edit it here\n",
    "    2.  saves us time from rewriting this a bunch\n",
    "    Parameters:\n",
    "    stateobj: a state object\n",
    "    years: the specified years.  Either a range or none\n",
    "    '''\n",
    "    subset_dat = stateobj.data\n",
    "    if years is not None:  \n",
    "        # if the user specifies a year range, filter the data for those years\n",
    "        subset_dat = stateobj.data[stateobj.data[stateobj.paths['year'][0]].isin(years)]\n",
    "    return subset_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfdb650",
   "metadata": {},
   "source": [
    "## plot_df\n",
    "This is the main plotting function for generalizable_multi_level_summary and subset_multi_level_summary.  This function takes a state, the percentages to plot, the plot type, and any subgroups to make plots for (in case we are grouping by more than just departure).\n",
    "\n",
    "Using this data, it creates the desired plots for the user to view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ad6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(stateobj, df, plot_type, groups):\n",
    "    '''\n",
    "    Main plotting function.  This is used by generalizable_multi_level_summary to take a dataframe and generate \n",
    "    graphs by calling plot_departures or plot_departures_stacked.\n",
    "    Parameters:\n",
    "    df: input dataframe.  Right now we are using percents from generalizable_multi_level_summary\n",
    "    stacked: if true, produce stacked bar graphs, if false, produce nonstacked bar graphs\n",
    "    groups: the parameters we are grouping by, we use these to generate titles in stacked bar graphs\n",
    "    \n",
    "    we have 6 main situations here\n",
    "    1. stacked bar, just departure to group by\n",
    "    2. stacked bar, more than just deaprture to group by\n",
    "    3. not stacked bar, just departure\n",
    "    4. not stacked bar, more than just departure\n",
    "    5. pie chart, just departure\n",
    "    6. pie chart, more than just departure\n",
    "    \n",
    "    each situation is handeled in the plotting phase\n",
    "    '''\n",
    "    unique_identifiers = []  # list of unique tuples in df.index we will need\n",
    "    unique_identifier_strings = []  # string fromat of unique_identifiers, used in graph titles.\n",
    "    if  df.index.nlevels > 1:\n",
    "        for ind in df.index:\n",
    "            if ind[:-1] not in unique_identifiers:  # we do ind[:-1] here because the last identifier is always departure, and we want our grops to be everything but departure \n",
    "                unique_identifiers.append(ind[:-1])  # add the unique identifier tuple\n",
    "                # create and add string form of the unique identifier to unique_identifier_strings\n",
    "                unique_identifier_string = ''\n",
    "                for string in ind[:-1]:\n",
    "                    unique_identifier_string += str(string) + ' '\n",
    "                unique_identifier_string = unique_identifier_string[:-1]\n",
    "                unique_identifier_strings.append(unique_identifier_string)\n",
    "    else:\n",
    "        unique_identifier_strings = [stateobj.order_of_outputs]\n",
    "                \n",
    "    # plotting time.\n",
    "    if plot_type == 'stacked bar':\n",
    "        if len(groups) > 0:  #we're dealing with more then one grouping variable\n",
    "            porportions = np.zeros((len(stateobj.order_of_outputs), len(unique_identifiers)))\n",
    "            for dep in range(len(stateobj.order_of_outputs)):\n",
    "                for unique_id in range(len(unique_identifiers)):\n",
    "                    loc_id = unique_identifiers[unique_id] + (stateobj.order_of_outputs[dep],)\n",
    "                    if loc_id in df.index:\n",
    "                        porportions[dep, unique_id] = df.loc[loc_id,]\n",
    "            #plot\n",
    "            groups.insert(0, stateobj.name)  # we need the state name for plotting purposes\n",
    "            plot_departures_stacked(unique_identifier_strings, porportions, groups, stateobj.order_of_outputs)\n",
    "        else:  # just departure\n",
    "            porportions = []\n",
    "            for departure_type in stateobj.order_of_outputs:\n",
    "                porportions.append(df.loc[departure_type,])\n",
    "            #plot\n",
    "            groups.insert(0, stateobj.name)  # we need the state name for plotting purposes\n",
    "            plot_departures_stacked([stateobj.name], porportions, groups, stateobj.order_of_outputs, s = False)\n",
    "            \n",
    "    if plot_type == 'bar' or plot_type == 'pie':  # not stacked bars\n",
    "        if len(groups) > 0:  #we're dealing with more then one grouping variable\n",
    "            for unique_id in unique_identifiers:\n",
    "                porportions = [0,0,0,0]\n",
    "                pos = 0\n",
    "                for deperture_type in stateobj.order_of_outputs:\n",
    "                    comb_ind = unique_id + (deperture_type,)\n",
    "                    if comb_ind in df.index:\n",
    "                        porportions[pos] = df.loc[comb_ind,]\n",
    "                    pos += 1\n",
    "                    \n",
    "                unique_id = (stateobj.name,) + unique_id\n",
    "                if plot_type == 'bar':\n",
    "                    plot_departures_bar(stateobj.order_of_outputs, porportions, unique_id)\n",
    "                else:  # pie\n",
    "                    plot_departures_pie(stateobj.order_of_outputs, porportions, unique_id)\n",
    "        else:\n",
    "            porportions = []\n",
    "            for departure_type in stateobj.order_of_outputs:\n",
    "                porportions.append(df.loc[departure_type,])\n",
    "            if plot_type == 'bar':\n",
    "                plot_departures_bar(stateobj.order_of_outputs, porportions, [stateobj.name], s = False) \n",
    "            else:  # pie\n",
    "                plot_departures_pie(stateobj.order_of_outputs, porportions, [stateobj.name], s = False)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d629cf4e",
   "metadata": {},
   "source": [
    "## calc_state_avg_for_yearspan\n",
    "\n",
    "This function calculates the state's averages for a select span of years.  It uses the state's yearly_average_percents and calculates the mean for the selected years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2224a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_state_avg_for_yearspan(stateobj, years):\n",
    "    avg_for_yearspan = []\n",
    "    for year in years:\n",
    "        avg_for_yearspan.append(stateobj.yearly_average_percents[year])\n",
    "    avg_for_yearspan = np.array(avg_for_yearspan)\n",
    "    means = np.mean(avg_for_yearspan, axis = 0)  # take the average of each column\n",
    "    rounded = means.round(2)\n",
    "    return rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfcf5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83cfb078",
   "metadata": {},
   "source": [
    "# Analysis Functions\n",
    "\n",
    "This function plots the state trends over time.\n",
    "\n",
    "Parameters:\n",
    "* stateobj: the state in question.  We need the state's yearly_average_percents to plot the graph\n",
    "* compressed: if true, plot all lines on one graph.  If false, plot all lines on separate graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf9d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_trends(stateobj, compressed = False):\n",
    "    state_data_y = np.zeros((len(stateobj.years), len(stateobj.order_of_outputs)))\n",
    "    for year in range(len(stateobj.years)):\n",
    "        state_data_y[year] = stateobj.yearly_average_percents[stateobj.years[year]]\n",
    "\n",
    "    colors = ['lightcoral', 'lightgrey', 'cornflowerblue', 'turquoise']\n",
    "    if compressed:\n",
    "        fig, ax = plt.subplots(figsize=(10, 7))\n",
    "        for col in range(len(stateobj.order_of_outputs)):\n",
    "            ax.plot(stateobj.years, state_data_y[:,col], label=stateobj.order_of_outputs[col], color = colors[col])\n",
    "        ttl = stateobj.name + ' Trends'\n",
    "        ax.legend()\n",
    "        ax.set_title(ttl)\n",
    "        ax.set_xlabel('year')\n",
    "        ax.set_ylabel('percentage (%)')\n",
    "    else:\n",
    "        for col in range(len(stateobj.order_of_outputs)):\n",
    "            fig, ax = plt.subplots(figsize=(10, 7))\n",
    "            ax.plot(stateobj.years, state_data_y[:,col], color = colors[col])\n",
    "            ttl = stateobj.name + ' ' + stateobj.order_of_outputs[col] + ' over time.'\n",
    "            ax.set_title(ttl)\n",
    "            ax.set_xlabel('year')\n",
    "            ax.set_ylabel('percentage (%)')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17ce1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state_trends(states['minnesota'], compressed = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c4a3a",
   "metadata": {},
   "source": [
    "## generalizable_multi_level_summary\n",
    "\n",
    "Grouping by any combination (or none) of factor variables.  There is only one assumption to calling this function:\n",
    "* the last level passed into inp_list_of_groups.  Basically, calling with only \\['departure'\\] means we are not grouping by any factor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf292cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalizable_multi_level_summary(stateobj, inp_list_of_groups = ['departure'], years = None, plot = 'stacked bar'):\n",
    "    # we should have a subplots vs stacked parameter here maybe?  either do lots of individual graphs or stacked\n",
    "    subset_dat = filter_years(stateobj, years)  #first, filter for the years we are looking for\n",
    "    groups_to_filter_by = []  # this list keeps track of the column names in our stateobj.data we are grouping by\n",
    "    # get the column names in our stateobj.data we are grouping by\n",
    "    for group in inp_list_of_groups:\n",
    "        groups_to_filter_by.append(stateobj.paths[group][0])\n",
    "    #groups_to_filter_by.append(stateobj.paths['departure'][0])  # add departure as a group by on the end, as that is our \n",
    "                                                                # the variable we are looking at\n",
    "    \n",
    "    #grouping by \n",
    "    #divide by count(all_items_but_daparture) for departure percentages for each subgroup\n",
    "    counts = subset_dat.groupby(groups_to_filter_by).count()\n",
    "    perc = None #initializing, will get value in next lines\n",
    "    if len(inp_list_of_groups) > 1: # if we are goruping by more than departure\n",
    "        perc = round(100 * counts / subset_dat.groupby(groups_to_filter_by[:-1]).count(), 1)\n",
    "    else:\n",
    "        perc = round( (100 * counts/ subset_dat.shape[0]),2)  #if we are just grouping by departure, we divide by data frame length\n",
    "    \n",
    "    # renames the values that have levels\n",
    "    l=0\n",
    "    for group in inp_list_of_groups:\n",
    "        if stateobj.paths[group][1] is not None:\n",
    "            perc = perc.rename(stateobj.paths[group][1], level = l)\n",
    "            counts = counts.rename(stateobj.paths[group][1], level = l)\n",
    "        l += 1\n",
    "    # pull the data we need from our dataframes    \n",
    "    perc = perc.iloc[:,0]  # all columns are the same, so we pull the first one\n",
    "    counts = counts.iloc[:,0]  # all columns are the same, so we pull the first one\n",
    "    \n",
    "    #create an output dataframe to return\n",
    "    comb_df = pd.concat([counts,perc],axis=1)  # combine our two columns into a dataframe\n",
    "    comb_df.columns = ['count', 'percent']  # rename columns \n",
    "    if plot == 'stacked bar':\n",
    "        plot_df(stateobj, perc, 'stacked bar', inp_list_of_groups[:-1])  # call our plotting function\n",
    "    elif plot == 'bar':\n",
    "        plot_df(stateobj, perc, 'bar', inp_list_of_groups[:-1])\n",
    "    elif plot == 'pie':\n",
    "        plot_df(stateobj, counts, 'pie', inp_list_of_groups[:-1])\n",
    "\n",
    "    return comb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d157de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generalizable_multi_level_summary(states['minnesota'], inp_list_of_groups = ['departure'], years = None, plot = 'stacked bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088c6ad",
   "metadata": {},
   "source": [
    "## subset_data_multi_level_summary\n",
    "\n",
    "A slightly modified version of generalizable_multi_level_summary.  This is built to work with already filtered data.  It is used in individual_judge_analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_data_multi_level_summary(stateobj, subset_dat, inp_list_of_groups = ['departure'], plot = 'stacked bar'):\n",
    "    groups_to_filter_by = []  # this list keeps track of the column names in our stateobj.data we are grouping by\n",
    "    # get the column names in our stateobj.data we are grouping by\n",
    "    for group in inp_list_of_groups:\n",
    "        groups_to_filter_by.append(stateobj.paths[group][0])\n",
    "    #groups_to_filter_by.append(stateobj.paths['departure'][0])  # add departure as a group by on the end, as that is our \n",
    "                                                                # the variable we are looking at\n",
    "    \n",
    "    #grouping by \n",
    "    #divide by count(all_items_but_daparture) for departure percentages for each subgroup\n",
    "    counts = subset_dat.groupby(groups_to_filter_by).count()\n",
    "    perc = None #initializing, will get value in next lines\n",
    "    if len(inp_list_of_groups) > 1: # if we are goruping by more than departure\n",
    "        perc = round(100 * counts / subset_dat.groupby(groups_to_filter_by[:-1]).count(), 1)\n",
    "    else:\n",
    "        perc = round( (100 * counts/ subset_dat.shape[0]),2)  #if we are just grouping by departure, we divide by data frame length\n",
    "    \n",
    "    # renames the values that have levels\n",
    "    l=0\n",
    "    for group in inp_list_of_groups:\n",
    "        if stateobj.paths[group][1] is not None:\n",
    "            perc = perc.rename(stateobj.paths[group][1], level = l)\n",
    "            counts = counts.rename(stateobj.paths[group][1], level = l)\n",
    "        l += 1\n",
    "    # pull the data we need from our dataframes    \n",
    "    perc = perc.iloc[:,0]  # all columns are the same, so we pull the first one\n",
    "    counts = counts.iloc[:,0]  # all columns are the same, so we pull the first one\n",
    "    \n",
    "    #create an output dataframe to return\n",
    "    comb_df = pd.concat([counts,perc],axis=1)  # combine our two columns into a dataframe\n",
    "    comb_df.columns = ['count', 'percent']  # rename columns \n",
    "    if plot == 'stacked bar':\n",
    "        plot_df(stateobj, perc, 'stacked bar', inp_list_of_groups[:-1])  # call our plotting function\n",
    "    elif plot == 'bar':\n",
    "        plot_df(stateobj, perc, 'bar', inp_list_of_groups[:-1])\n",
    "    elif plot == 'pie':\n",
    "        plot_df(stateobj, counts, 'pie', inp_list_of_groups[:-1])\n",
    "\n",
    "    return comb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1348a62",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Judge Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_judge_analysis(stateobj, judge_name, inp_list_of_groups = ['departure'], years = None, plot = True):\n",
    "    judge_filtered_data = stateobj.data[stateobj.data[stateobj.paths['judge'][0]]== judge_name]\n",
    "    # get the years where the judge was active\n",
    "    overlapping_years = years\n",
    "    if years is None:\n",
    "        overlapping_years = np.sort(judge_filtered_data[stateobj.paths['year'][0]].unique())\n",
    "    print(judge_name, 'was active in the years:', overlapping_years)\n",
    "    \n",
    "    groups_to_filter_by = []  # this list keeps track of the column names in our stateobj.data we are grouping by\n",
    "    # get the column names in our stateobj.data we are grouping by\n",
    "    for group in inp_list_of_groups:\n",
    "        groups_to_filter_by.append(stateobj.paths[group][0])\n",
    "    #groups_to_filter_by.append(stateobj.paths['departure'][0])  # add departure as a group by on the end, as that is our \n",
    "                                                                # the variable we are looking at\n",
    "    \n",
    "    #time to get the aggregate\n",
    "    \n",
    "    \n",
    "    #grouping by \n",
    "    #divide by count(all_items_but_daparture) for departure percentages for each subgroup\n",
    "    counts = judge_filtered_data.groupby(stateobj.paths['departure'][0]).count()\n",
    "    perc = round( (100 * counts/ judge_filtered_data.shape[0]),2)  #if we are just grouping by departure, \n",
    "                                                                   #we divide by data frame length\n",
    "    # renames the values that have levels\n",
    "    perc = perc.rename(stateobj.paths['departure'][1], level = 0)\n",
    "    counts = counts.rename(stateobj.paths['departure'][1], level = 0)\n",
    "\n",
    "    # pull the data we need from our dataframes    \n",
    "    perc = perc.iloc[:,0]  # all columns are the same, so we pull the first one\n",
    "    counts = counts.iloc[:,0]  # all columns are the same, so we pull the first one\n",
    "    \n",
    "    #create an output dataframe to return\n",
    "    agg_comb_df = pd.concat([counts,perc],axis=1)  # combine our two columns into a dataframe\n",
    "    agg_comb_df.columns = ['count', 'percent']  # rename columns \n",
    "    \n",
    "    state_avg_for_years = calc_state_avg_for_yearspan(stateobj, overlapping_years)\n",
    "    judge_averages = []\n",
    "    for departure_type in stateobj.order_of_outputs:\n",
    "        judge_averages.append(perc.loc[departure_type,])\n",
    "    \n",
    "    if plot:\n",
    "        plot_judge_vs_state(stateobj.order_of_outputs, judge_averages, \n",
    "                            state_avg_for_years, judge_name, stateobj.name)\n",
    "    \n",
    "    #now we plot the changes over time vs the state\n",
    "    judge_data_y = np.zeros((len(overlapping_years), len(stateobj.order_of_outputs)))\n",
    "    state_data_y = np.zeros((len(overlapping_years), len(stateobj.order_of_outputs)))\n",
    "    for year in range(len(overlapping_years)):\n",
    "        judge_year_data = judge_filtered_data[judge_filtered_data[stateobj.paths['year'][0]]== overlapping_years[year]]\n",
    "        perc = round( (100 * judge_year_data.groupby(stateobj.paths['departure'][0]).count()/ judge_year_data.shape[0]),2)\n",
    "        perc = perc.rename(stateobj.paths['departure'][1], level = 0)\n",
    "        perc = perc.iloc[:,0]\n",
    "        \n",
    "        for departure_type in range(len(stateobj.order_of_outputs)):\n",
    "            if stateobj.order_of_outputs[departure_type] in perc.index:\n",
    "                judge_data_y[year, departure_type] = perc.loc[stateobj.order_of_outputs[departure_type]]\n",
    "        \n",
    "        state_data_y[year] = stateobj.yearly_average_percents[overlapping_years[year]]\n",
    "\n",
    "    for departure_type in range(len(stateobj.order_of_outputs)):\n",
    "        if judge_data_y[-1, departure_type] >= state_data_y[-1, departure_type]:\n",
    "            print(judge_name, 'currently has a(n)', stateobj.order_of_outputs[departure_type], 'rate at or above state average in years queried')\n",
    "        else:\n",
    "            print(judge_name, 'currently has a(n)', stateobj.order_of_outputs[departure_type], 'rate below state average in years queried')\n",
    "    \n",
    "    if plot:\n",
    "        plot_judge_vs_state_trends(stateobj, overlapping_years, judge_data_y, state_data_y, judge_name) \n",
    "        subset_data_multi_level_summary(stateobj, judge_filtered_data, inp_list_of_groups, plot = 'stacked bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753d918",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "individual_judge_analysis(states['minnesota'], 'Cunningham, James',\n",
    "                                    inp_list_of_groups = ['race','departure'], years = None, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a01f9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101390f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
