{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47726396",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def individual_section_analysis_v2(self, category_name, section_name, inp_list_of_groups = ['departure'], years = None, plot = True):\n",
    "        '''\n",
    "        Outputs bar graph, stacked bar graph, and line graph of a Judges sentencing length over specified years\n",
    "\n",
    "        Parameters:\n",
    "            stateobj: a state object\n",
    "            section_name: name of the judge, for formatting the title\n",
    "            inp_list_of_groups: default is the sentencing departure ranges, can add other columns values to compare\n",
    "            years: the specified years.  Either a range or none\n",
    "            plot: Choose type of plot based off of ('stacked bar', 'bar', 'pie')\n",
    "\n",
    "        Returns:\n",
    "            Plots of subset of specified data for judges sentencing length\n",
    "        '''\n",
    "        section_filtered_data = self.data[self.data[self.paths[category_name].df_colname]== section_name]\n",
    "        rest_of_the_state = self.data[self.data[self.paths[category_name].df_colname]!= section_name]\n",
    "        # get the years where the judge was active\n",
    "        overlapping_years = years\n",
    "        if years is None:\n",
    "            overlapping_years = np.sort(section_filtered_data[self.paths['year'].df_colname].unique())\n",
    "        print(section_name, 'was active in the years:', overlapping_years)\n",
    "\n",
    "        groups_to_filter_by = []  # this list keeps track of the column names in our stateobj.data we are grouping by\n",
    "        # get the column names in our stateobj.data we are grouping by\n",
    "        total_number_of_subgroups = 1\n",
    "        for group in inp_list_of_groups:\n",
    "            groups_to_filter_by.append(self.paths[group].df_colname)\n",
    "            total_number_of_subgroups = total_number_of_subgroups * len(self.paths[group].levels) # i.e, if race has 5 levels, sex has 2, this should be 10\n",
    "        \n",
    "        #compare the whole stretch of years\n",
    "        \n",
    "        \n",
    "        \n",
    "        #first, filter for the span of years we are looking at\n",
    "        section_filtered_data = section_filtered_data[section_filtered_data[self.paths['year'].df_colname].isin(overlapping_years)]\n",
    "        rest_of_the_state = rest_of_the_state[rest_of_the_state[self.paths['year'].df_colname].isin(overlapping_years)]\n",
    "        \n",
    "        \n",
    "        #now, we call subset data analysis to get \n",
    "        section_allyr_stats = subset_data_multi_level_summary(self, section_filtered_data, section_name, inp_list_of_groups, plot = None)\n",
    "        rest_allyr_stats = subset_data_multi_level_summary(self, rest_of_the_state, self.name, inp_list_of_groups, plot = None)\n",
    "        \n",
    "        \n",
    "        #build unique tuples list\n",
    "        unique_identifiers = []  # list of unique tuples in df.index we will need\n",
    "        unique_identifier_strings = []  # string fromat of unique_identifiers, used in graph titles.\n",
    "        \n",
    "        if  rest_allyr_stats.index.nlevels > 1:\n",
    "            for ind in rest_allyr_stats.index:\n",
    "                if ind[:-1] not in unique_identifiers:  # we do ind[:-1] here because the last identifier is always departure, and we want our grops to be everything but departure \n",
    "                    unique_identifiers.append(ind[:-1])  # add the unique identifier tuple\n",
    "                    # create and add string form of the unique identifier to unique_identifier_strings\n",
    "                    unique_identifier_string = ''\n",
    "                    for string in ind[:-1]:\n",
    "                        unique_identifier_string += str(string) + ' '\n",
    "                    unique_identifier_string = unique_identifier_string[:-1]\n",
    "                    unique_identifier_strings.append(unique_identifier_string)\n",
    "                    \n",
    "            for unique_id in unique_identifiers:\n",
    "                print('Looking at',section_name, 'vs', self.name, 'for', unique_id,'s')\n",
    "                for departure_type in self.order_of_outputs:\n",
    "                    loc_id = unique_id + (departure_type,)\n",
    "                    if loc_id in section_allyr_stats.index and loc_id in rest_allyr_stats.index:\n",
    "                        if section_allyr_stats.loc[loc_id, 'percent'] > 1.05 * rest_allyr_stats.loc[loc_id, 'percent']:\n",
    "                            print(section_name, category_name,'currently has an average', departure_type, 'rate above state average in years queried')\n",
    "                        elif section_allyr_stats.loc[loc_id, 'percent'] < 0.95 * rest_allyr_stats.loc[loc_id, 'percent']:\n",
    "                            print(section_name, category_name,'currently has an average', departure_type, 'rate below state average in years queried')\n",
    "                        else: \n",
    "                            print(section_name, category_name,'currently has an average', departure_type, 'rate about at state average in years queried')\n",
    "\n",
    "        else:\n",
    "            unique_identifier_strings = [self.name]\n",
    "            print('Looking at',section_name, 'vs', self.name,'all')\n",
    "            for departure_type in self.order_of_outputs:\n",
    "                if departure_type in section_allyr_stats.index and departure_type in rest_allyr_stats.index:\n",
    "                    if section_allyr_stats.loc[departure_type, 'percent'] > 1.05 * rest_allyr_stats.loc[departure_type, 'percent']:\n",
    "                        print(section_name, category_name,'currently has an average', departure_type, 'rate above state average in years queried')\n",
    "                    elif section_allyr_stats.loc[departure_type, 'percent'] < 0.95 * rest_allyr_stats.loc[departure_type, 'percent']:\n",
    "                        print(section_name, category_name,'currently has an average', departure_type, 'rate below state average in years queried')\n",
    "                    else: \n",
    "                        print(section_name, category_name,'currently has an average', departure_type, 'rate about at state average in years queried')\n",
    "\n",
    "        #  now we get the data for graphing: multiple levels in inp_list_of_groups\n",
    "        if rest_allyr_stats.index.nlevels > 1:\n",
    "            #  now we create the data for the by year graphs\n",
    "            years_lst = []  #list of lists for each year we will append a lis tof [year, section_breakdown, rest_breakdown]\n",
    "            ret_pandas_data = {}\n",
    "            \n",
    "            for year in overlapping_years:\n",
    "                #  first, filter our data for the year we want\n",
    "                year_section_data = section_filtered_data[section_filtered_data[self.paths['year'].df_colname]==year]\n",
    "                year_rest_of_state_data = rest_of_the_state[rest_of_the_state[self.paths['year'].df_colname]==year]\n",
    "                \n",
    "                #  now we group by to get section breakdowns\n",
    "                year_section_breakdown = subset_data_multi_level_summary(self, year_section_data, section_name, inp_list_of_groups, plot = None)\n",
    "                year_restof_breakdown = subset_data_multi_level_summary(self, year_rest_of_state_data, self.name, inp_list_of_groups, plot = None)\n",
    "    \n",
    "    \n",
    "                section_data = np.zeros((len(self.order_of_outputs), len(unique_identifiers)))\n",
    "                rest_of_data = np.zeros((len(self.order_of_outputs), len(unique_identifiers)))\n",
    "                \n",
    "                for dep in range(len(self.order_of_outputs)):\n",
    "                    for unique_id in range(len(unique_identifiers)):\n",
    "                        loc_id = unique_identifiers[unique_id] + (self.order_of_outputs[dep],)\n",
    "                        if loc_id in year_section_breakdown.index:\n",
    "                            section_data[dep, unique_id] = year_section_breakdown.loc[loc_id,'percent']\n",
    "                        if loc_id in year_restof_breakdown.index:\n",
    "                            rest_of_data[dep, unique_id] = year_restof_breakdown.loc[loc_id,'percent']\n",
    "    \n",
    "                years_lst.append([year, section_data, rest_of_data])\n",
    "                ret_pandas_data[year] = [year_section_breakdown, year_restof_breakdown]\n",
    "                \n",
    "            #  now it's time to make graphs\n",
    "            \n",
    "            for unique_id in range(len(unique_identifiers)):\n",
    "                section_y_data = np.zeros((len(self.order_of_outputs), len(overlapping_years)))\n",
    "                rest_y_data = np.zeros((len(self.order_of_outputs), len(overlapping_years)))\n",
    "                for year in range(len(years_lst)):\n",
    "                    for departure_type in range(len(self.order_of_outputs)):\n",
    "                        section_y_data[departure_type][year] = years_lst[year][1][departure_type][unique_id]\n",
    "                        rest_y_data[departure_type][year] = years_lst[year][2][departure_type][unique_id]\n",
    "                if plot:\n",
    "                    print('plotting')\n",
    "                    plot_section_and_rest_data(overlapping_years,section_y_data,rest_y_data, self.colors, \n",
    "                                               unique_identifier_strings[unique_id], self.order_of_outputs, section_name, self.name)\n",
    "            return ret_pandas_data     \n",
    "\n",
    "        else:  # this is if we are only grouping by departure\n",
    "            section_data = np.zeros((len(self.order_of_outputs), len(overlapping_years)))\n",
    "            rest_of_data = np.zeros((len(self.order_of_outputs), len(overlapping_years)))\n",
    "            \n",
    "            for year in range(len(overlapping_years)):\n",
    "                year_section_data = section_filtered_data[section_filtered_data[self.paths['year'].df_colname]==overlapping_years[year]]\n",
    "                year_rest_of_state_data = rest_of_the_state[rest_of_the_state[self.paths['year'].df_colname]==overlapping_years[year]]\n",
    "                \n",
    "                #  now we group by to get section breakdowns\n",
    "                year_section_breakdown = subset_data_multi_level_summary(self, year_section_data, section_name, inp_list_of_groups, plot = None)\n",
    "                year_restof_breakdown = subset_data_multi_level_summary(self, year_rest_of_state_data, self.name, inp_list_of_groups, plot = None)\n",
    "                \n",
    "                for dep_type in range(len(self.order_of_outputs)):\n",
    "                    if self.order_of_outputs[dep_type] in year_section_breakdown.index:\n",
    "                        section_data[dep_type, year] = year_section_breakdown.loc[self.order_of_outputs[dep_type],'percent']\n",
    "                    if self.order_of_outputs[dep_type] in year_restof_breakdown.index:\n",
    "                        rest_of_data[dep_type, year] = year_restof_breakdown.loc[self.order_of_outputs[dep_type],'percent']\n",
    "            if plot:\n",
    "                print('plotting')\n",
    "                plot_section_and_rest_data(overlapping_years,section_data,rest_of_data, self.colors, \n",
    "                                           'all', self.order_of_outputs, section_name, self.name)\n",
    "            return section_allyr_stats, rest_allyr_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec10ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Individual Section Analysis\n",
    "\n",
    "    def individual_section_analysis(self, category_name, section_name, inp_list_of_groups = ['departure'], years = None, plot = True):\n",
    "        '''\n",
    "        Outputs bar graph, stacked bar graph, and line graph of a Judges sentencing length over specified years\n",
    "\n",
    "        Parameters:\n",
    "            stateobj: a state object\n",
    "            section_name: name of the judge, for formatting the title\n",
    "            inp_list_of_groups: default is the sentencing departure ranges, can add other columns values to compare\n",
    "            years: the specified years.  Either a range or none\n",
    "            plot: Choose type of plot based off of ('stacked bar', 'bar', 'pie')\n",
    "\n",
    "        Returns:\n",
    "            Plots of subset of specified data for judges sentencing length\n",
    "        '''\n",
    "        section_filtered_data = self.data[self.data[self.paths[category_name].df_colname]== section_name]\n",
    "        # get the years where the judge was active\n",
    "        overlapping_years = years\n",
    "        if years is None:\n",
    "            overlapping_years = np.sort(section_filtered_data[self.paths['year'].df_colname].unique())\n",
    "        print(section_name, 'was active in the years:', overlapping_years)\n",
    "\n",
    "        groups_to_filter_by = []  # this list keeps track of the column names in our stateobj.data we are grouping by\n",
    "        # get the column names in our stateobj.data we are grouping by\n",
    "        for group in inp_list_of_groups:\n",
    "            groups_to_filter_by.append(self.paths[group].df_colname)\n",
    "        #groups_to_filter_by.append(stateobj.paths['departure'][0])  # add departure as a group by on the end, as that is our \n",
    "                                                                    # the variable we are looking at\n",
    "\n",
    "        #time to get the aggregate\n",
    "\n",
    "\n",
    "        #grouping by \n",
    "        #divide by count(all_items_but_daparture) for departure percentages for each subgroup\n",
    "        counts = section_filtered_data.groupby(self.paths['departure'].df_colname).count()\n",
    "        perc = round( (100 * counts/ section_filtered_data.shape[0]),2)  #if we are just grouping by departure, \n",
    "                                                                       #we divide by data frame length\n",
    "        # renames the values that have levels\n",
    "        perc = perc.rename(self.paths['departure'].levels, level = 0)\n",
    "        counts = counts.rename(self.paths['departure'].levels, level = 0)\n",
    "\n",
    "        # pull the data we need from our dataframes    \n",
    "        perc = perc.iloc[:,0]  # all columns are the same, so we pull the first one\n",
    "        counts = counts.iloc[:,0]  # all columns are the same, so we pull the first one\n",
    "\n",
    "        #create an output dataframe to return\n",
    "        agg_comb_df = pd.concat([counts,perc],axis=1)  # combine our two columns into a dataframe\n",
    "        agg_comb_df.columns = ['count', 'percent']  # rename columns \n",
    "\n",
    "        state_avg_for_years = self.calc_state_avg_for_yearspan(overlapping_years)\n",
    "        section_averages = []\n",
    "        for departure_type in self.order_of_outputs:\n",
    "            section_averages.append(perc.loc[departure_type,])\n",
    "\n",
    "        if plot:\n",
    "            plot_section_vs_state(self.order_of_outputs, section_averages, \n",
    "                                state_avg_for_years, section_name, self.name)\n",
    "\n",
    "        #now we plot the changes over time vs the state\n",
    "        section_data_y = np.zeros((len(overlapping_years), len(self.order_of_outputs)))\n",
    "        state_data_y = np.zeros((len(overlapping_years), len(self.order_of_outputs)))\n",
    "        for year in range(len(overlapping_years)):\n",
    "            section_year_data = section_filtered_data[section_filtered_data[self.paths['year'][0]]== overlapping_years[year]]\n",
    "            perc = round( (100 * section_year_data.groupby(self.paths['departure'][0]).count()/ section_year_data.shape[0]),2)\n",
    "            perc = perc.rename(self.paths['departure'][1], level = 0)\n",
    "            perc = perc.iloc[:,0]\n",
    "\n",
    "            for departure_type in range(len(self.order_of_outputs)):\n",
    "                if self.order_of_outputs[departure_type] in perc.index:\n",
    "                    section_data_y[year, departure_type] = perc.loc[self.order_of_outputs[departure_type]]\n",
    "\n",
    "            state_data_y[year] = self.yearly_average_percents[overlapping_years[year]]\n",
    "\n",
    "        for departure_type in range(len(self.order_of_outputs)):\n",
    "            if section_data_y[-1, departure_type] >= state_data_y[-1, departure_type]:\n",
    "                print(section_name, 'currently has a(n)', self.order_of_outputs[departure_type], 'rate at or above state average in years queried')\n",
    "            else:\n",
    "                print(section_name, 'currently has a(n)', self.order_of_outputs[departure_type], 'rate below state average in years queried')\n",
    "\n",
    "        if plot:\n",
    "            plot_section_vs_state_trends(overlapping_years, section_data_y, state_data_y, section_name) \n",
    "            subset_data_multi_level_summary(section_filtered_data, inp_list_of_groups, plot = 'stacked bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_aggregate(stateobj, years = None, stacked = False):\n",
    "    subset_dat = filter_years(stateobj, years)\n",
    "    \n",
    "    counts = subset_dat.groupby(stateobj.paths['departure'][0]).count()\n",
    "    counts = counts.rename(stateobj.paths['departure'][1])\n",
    "    counts = counts.iloc[:,0]\n",
    "     \n",
    "    order_of_outputs = ['Above Departure', 'Within Range', 'Below Range', 'Missing, Indeterminable, or Inapplicable']\n",
    "    porportions_list = []\n",
    "    for item in order_of_outputs:\n",
    "        porportions_list.append(round((100 * counts.at[item]  /  subset_dat.shape[0]),1))\n",
    "    \n",
    "    if stacked:\n",
    "        arr = np.array(porportions_list)\n",
    "        arr = arr.T\n",
    "        plot_departures_stacked([stateobj.name], porportions_list, [stateobj.name], order_of_outputs)\n",
    "    else:\n",
    "        plot_departures(order_of_outputs, porportions_list, [stateobj.name], s = False)\n",
    "    \n",
    "    return counts, porportions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_aggregate(states['minnesota'], stacked = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_profile(stateobj, years = None, stacked = True):\n",
    "    subset_dat = filter_years(stateobj, years)\n",
    "    #grouping by departure and race\n",
    "    #divide by count(race) for racial percentages, to get counts, remove the denominator\n",
    "    counts = subset_dat.groupby([stateobj.paths['race'][0], stateobj.paths['departure'][0]]).count()\n",
    "    perc = round(100 * counts / subset_dat.groupby([stateobj.paths['race'][0]]).count(), 1)\n",
    "    \n",
    "    # renames the values to have a description\n",
    "    perc = perc.rename(stateobj.paths['race'][1], level = 0)\n",
    "    perc = perc.rename(stateobj.paths['departure'][1], level = 1)\n",
    "    perc = perc.iloc[:,0]  # all columns are the same, so we pull the first one\n",
    "    \n",
    "    counts = counts.rename(stateobj.paths['race'][1], level = 0)\n",
    "    counts = counts.rename(stateobj.paths['departure'][1], level = 1)\n",
    "    counts = counts.iloc[:,0]  # all columns are the same, so we pull the first one\n",
    "    \n",
    "    comb_df = pd.concat([counts,perc],axis=1)\n",
    "    comb_df.columns = ['count', 'percent']\n",
    "    \n",
    "    order_of_outputs = ['Above Departure', 'Within Range', 'Below Range', 'Missing, Indeterminable, or Inapplicable']\n",
    "    \n",
    "    #get the order of the races four out output, may make this a function\n",
    "    order_of_races = []\n",
    "    for idx in perc.index:  #idx is a tuple of (race, departure_type)\n",
    "        if idx[0] not in order_of_races:\n",
    "            order_of_races.append(idx[0])\n",
    "            \n",
    "    # we want our data to be in the shape: number of levels in output (departure) x number of subgroups (race)        \n",
    "    percentages = np.zeros((len(order_of_outputs), len(order_of_races)))\n",
    "    for dep in range(len(order_of_outputs)):\n",
    "        for race in range(len(order_of_races)):\n",
    "            percentages[dep, race] = perc.loc[(order_of_races[race], order_of_outputs[dep]),]\n",
    "    #warning, potential for keyerror above if sonehow we have a race that doesn't have all departure levels        \n",
    "    print(order_of_races)\n",
    "    print(type(order_of_races))\n",
    "    if stacked:\n",
    "        plot_departures_stacked(order_of_races, percentages, [stateobj.name, 'race'], order_of_outputs)\n",
    "    else:\n",
    "        for i in range(len(order_of_races)):\n",
    "            plot_departures(order_of_outputs, percentages[:,i], [stateobj.name, order_of_races[i]])\n",
    "    return comb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6cf2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_profile(states['minnesota'], stacked = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
